{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料預處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座8 - 取得範例資料檔\n",
    "\n",
    "範例程式及資料檔下載網址：\n",
    "[https://www.superdatascience.com/machine-learning/](https://www.superdatascience.com/machine-learning/)\n",
    "\n",
    "先下載目錄結構，解壓縮到你要的位置。\n",
    "\n",
    "接下來選擇你想要的章節，下載檔案解壓縮到對應的資料夾內就可以了，後續每個章節的範例程式及資料檔也都比照辦理。\n",
    "\n",
    "拿到資料後可以先看一下資料長什麼樣子。打開Data.csv：\n",
    "![](images/Data.PNG)\n",
    "\n",
    "這是一組10列(row)4行(column)的薪資資料。在後續大多數章節的課程中，我們就要嘗試利用independent variables(Country, Age, Salary)來對dependent variable(Purchased)進行預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補充 - Spyder IDE\n",
    "\n",
    "現場demo\n",
    "- 介面環境介紹\n",
    "- 偏好設定\n",
    "- 語法執行方式\n",
    "- 變數檢視及其型態\n",
    "- 說明視窗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座9 - 載入套件\n",
    "\n",
    "套件就是工具模組的集合，課程列出了三個機器學習常用的套件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numpy包含了一些常用的數學運算工具\n",
    "- matplotlib.pyplot是用於繪圖的套件\n",
    "- pandas適合用於資料管理、分析\n",
    "\n",
    "np, plt, pd分別是我們自己給定的套件別名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補充 - 設定工作目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()  # 取得當前工作目錄\n",
    "os.chdir('path')  # 切換工作目錄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座10 - 讀取資料\n",
    "\n",
    "首先使用pd套件的read_csv來讀取資料，read_csv的詳細說明[點這裡](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)。\n",
    "\n",
    "接著要定義出independent variables(X)和dependent variable(y)。\n",
    "使用[iloc](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html)取indexing, 用[values](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.values.html)轉換為Numpy表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指標系統(indexing)以中括號[]表示，不同維度以逗號區隔。\n",
    "\n",
    "在python裡面的index是由0開始，可以用冒號(:)表示一個序列，例如[0:3]代表0, 1, 2(沒有包含3)。\n",
    "\n",
    "負號則代表排除，例如[0:-1]代表排除最後一個元素。\n",
    "\n",
    "沒有寫index的話則是盡量取最多，例如[:5]表示取0, 1, 2, 3, 4。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座11 - 物件導向 OOP\n",
    "\n",
    "類別(class)是一種我們想要用來建立某種東西的模板。舉例來說，如果我們制定了一個房屋建設計畫，那這個施工計畫就是一個類別。\n",
    "\n",
    "物件(object)是類別的一個實例。所以同樣以房屋建設計畫為例，這時物件就是一個房子。一間房子(物件)是按照施工計畫(類別)所建造而成的。\n",
    "因此可以有很多不同的物件屬於同一個類別，因為我們可以用同一份施工計畫來建造不同的房子。\n",
    "\n",
    "方法(method)是一種使用在物件上的特定操作。承上例，當有客人造訪時打開門這個動作就是一種方法。我們也可以把方法視為作用在物件上的一個函數(function)：放入input、回傳output。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座12 - 遺失值處理\n",
    "\n",
    "回頭看看資料可以發現裡面有兩個遺失值。遇到資料有遺失值的時候有幾種處理方式，直接整列刪掉也是一種方法，不過貿然刪除資料會導致資訊的喪失，課程的講師覺得不太優，所以他推薦採用sklearn套件提供的[Imputer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html)插補方法。\n",
    "\n",
    "Imputer是一個class，fit和transform都是他的method，大家可以參考上面的連結說明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這段程式碼就是指定遺失值(missing_values='NaN')都會以該行(axis=0)的平均數(strategy='mean')進行插補。\n",
    "\n",
    "其實上面最後兩行也可以直接用fit_transform寫成底下這樣就好了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[:, 1:3] = imputer.fit_transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座13 - 類別資料處理\n",
    "\n",
    "因為資料分析的各種演算法不管是計算資料間的距離或是矩陣運算之類，都只能處理數值資料，所以我們要先把類別資料數值化。\n",
    "\n",
    "課程用到的一樣是sklearn套件的[LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)和[OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)。\n",
    "\n",
    "以Country為例，使用LabelEncoder轉為數值型態："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這時候雖然Country已經是數值型態可以直接丟去跑分析，但實際上不合理。因為每個國家之間沒有順序關係，所以不能單純用含有大小比例關係的數字編碼，而必須轉成dummy variable：\n",
    "![](images/dummy_variable.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dependent variable的部分就只要作LabelEncoder就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the Dependent Variable\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座14 - 將資料分為訓練及測試樣本\n",
    "\n",
    "如果我們在建立模型的時候把手上的所有資料都丟進去，那也許可以找到一個很完美的模型將目標變數100%正確的區分出來，例如下圖的綠線：\n",
    "![](images/overfitting.PNG)\n",
    "\n",
    "但其實黑線才是比較合理的模型，在預測一組新資料的時候通常可以獲得比綠線模型更好的效果。這邊綠線的情況就是所謂的overfitting。\n",
    "\n",
    "要避免這種情況，可以將資料分為訓練樣本用於建模、測試樣本用於驗證，以此檢驗模型是否有過度擬合的情形。\n",
    "\n",
    "課程中使用sklearn.cross_validation的[train_test_split](http://scikit-learn.org/0.17/modules/generated/sklearn.cross_validation.train_test_split.html)方法切割資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面最後一行用了一種比較特別的python變數指派方式，總之就是把回傳的list直接assign到這四個變數。\n",
    "\n",
    "test_size其實是隨便，課程建議是0.2~0.3左右。random_state就是可以設定一個固定的seed，有設定的話每次跑出來結果會一樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座15 - 變數尺度化\n",
    "\n",
    "各變數之間的尺度如果不一致，有時候會對模型的準確度或是收斂速度造成影響。例如某些方法會去計算資料點間的歐氏距離，圖解說明如下：\n",
    "![](images/distance.PNG)\n",
    "此時假設X是Age, Y是Salary，則依照距離的公式，Age會變成幾乎無法對模型造成影響。所以為了避免這種情況，我們要對變數做scaling。\n",
    "\n",
    "常用的scaling方法有兩種，都可以用：\n",
    "![](images/scaling.PNG)\n",
    "\n",
    "課程中使用sklearn.preprocessing的[StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)進行scaling。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至於需不需要對dummy variable作scaling，課程講師是說看情況，雖然我聽完還是不知道為什麼要。\n",
    "\n",
    "Y的部分則只有在regression的時候有可能會考慮作scaling。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 講座17 - 資料預處理樣板\n",
    "\n",
    "課程把整個資料預處理章節的程式整理成一份樣板檔，這樣以後每次要建模前都可以拿出來用，只要修改一些小地方就好了。\n",
    "\n",
    "其中有一些小節因為不一定會用到所以被刪掉了，有需要再另外加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing Template\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 3].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
